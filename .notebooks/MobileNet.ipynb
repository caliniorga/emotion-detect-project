{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image classification using MobileNet\n",
    "In essence, this code creates a model that uses a pre-trained MobileNet network for feature extraction and then adds fully connected layers for classification. The fully connected layer is the part that will be further trained to adapt to the specific data of your classification problem, while the MobileNet layers remain unchanged and are used to extract features from the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator , img_to_array, load_img\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input \n",
    "from keras.losses import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MobileNet model with an input shape of 224x224 pixels and 3 color channels (RGB).\n",
    "# The parameter include_top=False means that the fully connected classification layers are not included.\n",
    "model = MobileNet(input_shape=(224, 224, 3), include_top=False)\n",
    "\n",
    "# To prevent further training of the MobileNet layers, all layers in the model are set as non-trainable.\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add a Flatten layer to convert the model's output into a one-dimensional vector.\n",
    "x = Flatten()(model.output)\n",
    "\n",
    "# Add a Dense layer with 7 units and a 'softmax' activation function for final classification.\n",
    "x = Dense(units=7, activation='softmax')(x)\n",
    "\n",
    "# Create a new model that combines the MobileNet architecture with the added layers for classification.\n",
    "model = Model(model.input, x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=categorical_crossentropy, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data for training and testing\n",
    "This code prepares data for training and testing an image classification model using a pre-trained MobileNet architecture.\n",
    "\n",
    "Data Augmentation for Training: Training data is augmented with zooming, shearing, horizontal flipping, and pixel value rescaling, enhancing its diversity and quality.\n",
    "\n",
    "Loading Training Data: The training data is loaded from a specified directory. Images are resized to 224x224 pixels, and batches of 32 images are used.\n",
    "\n",
    "Data Augmentation for Testing: For testing data, only pixel value rescaling is applied.\n",
    "\n",
    "Loading Testing Data: Testing data is loaded from the designated directory.\n",
    "\n",
    "This approach leverages a pre-trained MobileNet network for feature extraction, with additional fully connected layers for classification. The fully connected layers are trained to adapt to the specific classification task, while the MobileNet layers remain unaltered to extract meaningful features from the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'angry': 0,\n",
       " 'disgust': 1,\n",
       " 'fear': 2,\n",
       " 'happy': 3,\n",
       " 'neutral': 4,\n",
       " 'sad': 5,\n",
       " 'surprise': 6}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_augumentation = ImageDataGenerator(zoom_range=0.2, shear_range=0.2, horizontal_flip=True, rescale=1./225)\n",
    "train_data = train_data_augumentation.flow_from_directory(directory=r\"C:\\Users\\Calin PC\\Documents\\emotion-detect-project\\data\\train\", target_size=(224,224), batch_size=32)\n",
    "train_data.class_indices\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7178 images belonging to 7 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'angry': 0,\n",
       " 'disgust': 1,\n",
       " 'fear': 2,\n",
       " 'happy': 3,\n",
       " 'neutral': 4,\n",
       " 'sad': 5,\n",
       " 'surprise': 6}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_augumentation = ImageDataGenerator(rescale = 1./225)\n",
    "test_data = test_data_augumentation.flow_from_directory(directory=r\"C:\\Users\\Calin PC\\Documents\\emotion-detect-project\\data\\test\", target_size=(224,224), batch_size=32)\n",
    "test_data.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Stopping and Model Check Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "es = EarlyStopping(monitor=\"val_loss\", min_delta=0.01, patience=5, verbose=1)\n",
    "mc = ModelCheckpoint(filepath=\"best_model.h5\", monitor= 'val_accuracy', verbose= 1, save_best_only= True, mode = 'auto')\n",
    "call_back = [es,mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Calin PC\\AppData\\Local\\Temp\\ipykernel_20648\\1036444180.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  hist = model.fit_generator(train_data,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10/10 [==============================] - ETA: 0s - loss: 18.3756 - accuracy: 0.2469\n",
      "Epoch 1: val_accuracy improved from -inf to 0.28906, saving model to best_model.h5\n",
      "10/10 [==============================] - 21s 2s/step - loss: 18.3756 - accuracy: 0.2469 - val_loss: 11.4051 - val_accuracy: 0.2891\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Calin PC\\Documents\\emotion-detect-project\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - ETA: 0s - loss: 11.1075 - accuracy: 0.2438\n",
      "Epoch 2: val_accuracy improved from 0.28906 to 0.31250, saving model to best_model.h5\n",
      "10/10 [==============================] - 18s 2s/step - loss: 11.1075 - accuracy: 0.2438 - val_loss: 7.2169 - val_accuracy: 0.3125\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - ETA: 0s - loss: 7.6830 - accuracy: 0.3625\n",
      "Epoch 3: val_accuracy did not improve from 0.31250\n",
      "10/10 [==============================] - 18s 2s/step - loss: 7.6830 - accuracy: 0.3625 - val_loss: 8.3527 - val_accuracy: 0.2422\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - ETA: 0s - loss: 6.6247 - accuracy: 0.3594\n",
      "Epoch 4: val_accuracy improved from 0.31250 to 0.43359, saving model to best_model.h5\n",
      "10/10 [==============================] - 18s 2s/step - loss: 6.6247 - accuracy: 0.3594 - val_loss: 5.4044 - val_accuracy: 0.4336\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - ETA: 0s - loss: 5.6561 - accuracy: 0.3875\n",
      "Epoch 5: val_accuracy improved from 0.43359 to 0.45312, saving model to best_model.h5\n",
      "10/10 [==============================] - 18s 2s/step - loss: 5.6561 - accuracy: 0.3875 - val_loss: 4.2047 - val_accuracy: 0.4531\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - ETA: 0s - loss: 4.6167 - accuracy: 0.4031\n",
      "Epoch 6: val_accuracy did not improve from 0.45312\n",
      "10/10 [==============================] - 17s 2s/step - loss: 4.6167 - accuracy: 0.4031 - val_loss: 5.6178 - val_accuracy: 0.3945\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - ETA: 0s - loss: 5.1081 - accuracy: 0.4437\n",
      "Epoch 7: val_accuracy did not improve from 0.45312\n",
      "10/10 [==============================] - 17s 2s/step - loss: 5.1081 - accuracy: 0.4437 - val_loss: 6.3640 - val_accuracy: 0.4180\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - ETA: 0s - loss: 5.2278 - accuracy: 0.4031\n",
      "Epoch 8: val_accuracy did not improve from 0.45312\n",
      "10/10 [==============================] - 17s 2s/step - loss: 5.2278 - accuracy: 0.4031 - val_loss: 4.9814 - val_accuracy: 0.3945\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - ETA: 0s - loss: 6.2962 - accuracy: 0.3969\n",
      "Epoch 9: val_accuracy did not improve from 0.45312\n",
      "10/10 [==============================] - 17s 2s/step - loss: 6.2962 - accuracy: 0.3969 - val_loss: 5.4581 - val_accuracy: 0.4297\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - ETA: 0s - loss: 5.9326 - accuracy: 0.4000\n",
      "Epoch 10: val_accuracy did not improve from 0.45312\n",
      "10/10 [==============================] - 17s 2s/step - loss: 5.9326 - accuracy: 0.4000 - val_loss: 6.4092 - val_accuracy: 0.4453\n",
      "Epoch 10: early stopping\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(train_data, \n",
    "                           steps_per_epoch= 10, \n",
    "                           epochs= 30, \n",
    "                           validation_data= test_data, \n",
    "                           validation_steps= 8, \n",
    "                           callbacks=[es,mc])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
